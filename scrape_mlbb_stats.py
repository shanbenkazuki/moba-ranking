import asyncio
import aiosqlite
import os
import logging
import aiohttp
from datetime import datetime
from playwright.async_api import async_playwright
from dotenv import load_dotenv
from scrape_mlbb_latest_patch import MLBBPatchScraper
from src.slack_webhook import send_slack_notification

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# --- ãƒ­ã‚°è¨­å®š ---
def setup_logging():
    """ãƒ­ã‚°è¨­å®šã‚’åˆæœŸåŒ–"""
    log_dir = os.path.join(os.path.dirname(__file__), 'logs')
    os.makedirs(log_dir, exist_ok=True)
    today = datetime.now().strftime('%Y-%m-%d')
    log_file = os.path.join(log_dir, f'mlbb/mlbb_scraping_{today}.log')
    
    # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    os.makedirs(os.path.dirname(log_file), exist_ok=True)
    
    # ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

class MLBBScraper:
    """Mobile Legends Bang Bang ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼"""
    
    def __init__(self):
        self.logger = setup_logging()
        self.browser = None
        self.page = None
        self.new_characters = []  # æ–°è¦ç™»éŒ²ã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ãƒªã‚¹ãƒˆ
        self.webhook_url = os.environ.get('SLACK_WEBHOOK_URL')
        
        if not self.webhook_url:
            self.logger.error('SLACK_WEBHOOK_URLç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“')
            raise ValueError('SLACK_WEBHOOK_URLç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“')
        
    async def launch_browser(self):
        """ãƒ–ãƒ©ã‚¦ã‚¶ã‚’èµ·å‹•"""
        playwright = await async_playwright().__aenter__()
        self.browser = await playwright.chromium.launch(headless=True)
        self.page = await self.browser.new_page()
        self.logger.info('Playwrightãƒ–ãƒ©ã‚¦ã‚¶ã®èµ·å‹•ã«æˆåŠŸ')
        
    async def close_browser(self):
        """ãƒ–ãƒ©ã‚¦ã‚¶ã‚’çµ‚äº†"""
        if self.browser:
            await self.browser.close()
            self.logger.info('Playwrightãƒ–ãƒ©ã‚¦ã‚¶ã‚’æ­£å¸¸ã«çµ‚äº†')
            
    async def navigate_to_ranking_page(self):
        """ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹"""
        await self.page.goto('https://m.mobilelegends.com/rank', wait_until='networkidle')
        self.logger.info('æŒ‡å®šURLã‚’ã‚ªãƒ¼ãƒ—ãƒ³')
        
    async def close_privacy_policy(self):
        """ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ã®ãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—ã‚’é–‰ã˜ã‚‹"""
        await self.page.wait_for_selector('div.mt-cb-policy-close')
        await self.page.click('#mt-cb-policy > div > div.mt-cb-policy-close')
        self.logger.info('ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ã®ãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—ã‚’ã‚¯ãƒ­ãƒ¼ã‚º')
        
    async def select_rank(self):
        """ãƒ©ãƒ³ã‚¯ã‚’é¸æŠï¼ˆMythicï¼‰"""
        # æŒ‡å®šã•ã‚ŒãŸXPathã®è¦ç´ ã‚’ã‚¯ãƒªãƒƒã‚¯
        xpath_selector = '//*[@id="root"]/div[1]/div[5]/div/div[1]/div[1]/div[2]/div[2]'
        await self.page.wait_for_selector(f'xpath={xpath_selector}', timeout=10000)
        self.logger.info('æŒ‡å®šã•ã‚ŒãŸXPathã®è¦ç´ ã‚’ç¢ºèª')
        
        await self.page.click(f'xpath={xpath_selector}')
        self.logger.info('æŒ‡å®šã•ã‚ŒãŸXPathã®è¦ç´ ã‚’ã‚¯ãƒªãƒƒã‚¯')
        
        # Mythicé¸æŠ
        mythic_xpath = '//*[@id="root"]/div[1]/div[5]/div/div[1]/div[1]/div[2]/div[1]/div/div[4]'
        await self.page.wait_for_selector(f'xpath={mythic_xpath}')
        await self.page.click(f'xpath={mythic_xpath}')
        self.logger.info('ã€Mythicã€ãƒ©ãƒ³ã‚¯ã‚’é¸æŠ')
        
    async def scroll_to_load_all_data(self):
        """ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã—ã¦å…¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        # Seleniumã®ãƒ­ã‚¸ãƒƒã‚¯ã«åˆã‚ã›ã¦XPathã‚’å¤‰æ›´
        scroll_target_xpath = '//*[@id="root"]/div[1]/div[5]/div/div[2]/div/div[2]/div'
        
        try:
            await self.page.wait_for_selector(f'xpath={scroll_target_xpath}')
            self.logger.info('ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯¾è±¡ã®è¦ç´ ã‚’å–å¾—')
            
            # Seleniumã®ãƒ­ã‚¸ãƒƒã‚¯ã¨åŒæ§˜ã®ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å‡¦ç†
            await self.page.evaluate("""
                async (xpath) => {
                    const target_element = document.evaluate(xpath, document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;
                    if (!target_element) {
                        throw new Error('ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯¾è±¡ã®è¦ç´ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“');
                    }
                    
                    let lastHeight = target_element.scrollHeight;
                    
                    while (true) {
                        target_element.scrollTo(0, target_element.scrollHeight);
                        await new Promise(resolve => setTimeout(resolve, 2000));
                        
                        let newHeight = target_element.scrollHeight;
                        if (newHeight === lastHeight) {
                            break;
                        }
                        lastHeight = newHeight;
                    }
                }
            """, scroll_target_xpath)
            
            self.logger.info('ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿å®Œäº†ï¼ˆã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å‡¦ç†çµ‚äº†ï¼‰')
            
        except Exception as scroll_error:
            self.logger.error(f'ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {scroll_error}')
            raise scroll_error
        
    async def extract_hero_data(self):
        """ãƒ’ãƒ¼ãƒ­ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        hero_meta_data = await self.page.evaluate("""
            () => {
                // è¦ªè¦ç´ ã®XPath
                const parentXpath = '//*[@id="root"]/div[1]/div[5]/div/div[2]/div/div[2]/div';
                const parentElement = document.evaluate(parentXpath, document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;
                
                if (!parentElement) {
                    console.error('è¦ªè¦ç´ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“');
                    return [];
                }
                
                // å­è¦ç´ ï¼ˆdivï¼‰ã®æ•°ã‚’å–å¾—
                const childDivs = parentElement.children;
                console.log(`å–å¾—å¯¾è±¡ã®å­è¦ç´ æ•°: ${childDivs.length}`);
                
                const data = [];
                
                // å„å­è¦ç´ ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                for (let i = 0; i < childDivs.length; i++) {
                    const index = i + 1; // XPathã¯1ãƒ™ãƒ¼ã‚¹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
                    
                    // å„è¦ç´ ã®XPathï¼ˆçµ¶å¯¾ãƒ‘ã‚¹ï¼‰
                    const heroNameXpath = `//*[@id="root"]/div[1]/div[5]/div/div[2]/div/div[2]/div/div[${index}]/div[2]/div[2]/span`;
                    const pickRateXpath = `//*[@id="root"]/div[1]/div[5]/div/div[2]/div/div[2]/div/div[${index}]/div[3]/span`;
                    const winRateXpath = `//*[@id="root"]/div[1]/div[5]/div/div[2]/div/div[2]/div/div[${index}]/div[4]/span`;
                    const banRateXpath = `//*[@id="root"]/div[1]/div[5]/div/div[2]/div/div[2]/div/div[${index}]/div[5]/span`;
                    const iconImageXpath = `//*[@id="root"]/div[1]/div[5]/div/div[2]/div/div[2]/div/div[${index}]/div[2]/div[1]/img`;
                                                    
                    
                    const heroNameElement = document.evaluate(heroNameXpath, document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;
                    const pickRateElement = document.evaluate(pickRateXpath, document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;
                    const winRateElement = document.evaluate(winRateXpath, document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;
                    const banRateElement = document.evaluate(banRateXpath, document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;
                    const iconImageElement = document.evaluate(iconImageXpath, document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;
                    
                    if (heroNameElement && pickRateElement && winRateElement && banRateElement) {
                        const hero_name = heroNameElement.textContent.trim();
                        const pick_rate = parseFloat(pickRateElement.textContent.replace("%", ""));
                        const win_rate = parseFloat(winRateElement.textContent.replace("%", ""));
                        const ban_rate = parseFloat(banRateElement.textContent.replace("%", ""));
                        const icon_src = iconImageElement ? iconImageElement.src : null;
                        
                        data.push({
                            hero: hero_name,
                            win_rate: win_rate,
                            pick_rate: pick_rate,
                            ban_rate: ban_rate,
                            icon_src: icon_src
                        });
                        
                        console.log(`ãƒ’ãƒ¼ãƒ­ãƒ¼ ${index}: ${hero_name} - Pick: ${pick_rate}%, Win: ${win_rate}%, Ban: ${ban_rate}%`);
                    } else {
                        console.warn(`ãƒ’ãƒ¼ãƒ­ãƒ¼ ${index}: å¿…è¦ãªè¦ç´ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“`);
                        console.warn(`  - heroName: ${!!heroNameElement}, pickRate: ${!!pickRateElement}, winRate: ${!!winRateElement}, banRate: ${!!banRateElement}`);
                    }
                }
                
                console.log(`åˆè¨ˆå–å¾—ãƒ‡ãƒ¼ã‚¿æ•°: ${data.length}`);
                return data;
            }
        """)
        
        self.logger.info(f'æŠ½å‡ºå¯¾è±¡ã®ãƒ’ãƒ¼ãƒ­ãƒ¼ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(hero_meta_data)}')
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šã—ã¦ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®å­˜åœ¨ç¢ºèªã¨ç”»åƒä¿å­˜
        data_dir = os.path.join(os.path.dirname(__file__), 'data')
        os.makedirs(data_dir, exist_ok=True)
        db_path = os.path.join(data_dir, 'moba_log.db')
        
        async with aiosqlite.connect(db_path) as db:
            await db.execute('PRAGMA foreign_keys = ON;')
            
            # MLBBã®ã‚²ãƒ¼ãƒ IDã‚’å–å¾—
            game_id = await self.get_mlbb_game_id(db)
            
            for hero in hero_meta_data:
                # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                async with db.execute(
                    'SELECT id FROM characters WHERE english_name = ? AND game_id = ?',
                    (hero['hero'], game_id)
                ) as cursor:
                    character_result = await cursor.fetchone()
                
                if not character_result and hero['icon_src']:
                    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒå­˜åœ¨ã—ãªã„å ´åˆã€ã‚¢ã‚¤ã‚³ãƒ³ç”»åƒã‚’ä¿å­˜
                    await self.save_hero_icon(hero['hero'], hero['icon_src'])
        
        return hero_meta_data
        
    async def extract_reference_date(self):
        """å‚ç…§æ—¥æ™‚ã‚’æŠ½å‡º"""
        reference_date_str = await self.page.evaluate("""
            () => {
                const xpath = '//*[@id="root"]/div[1]/div[5]/div/div[1]/div[2]/div[2]/span';
                const element = document.evaluate(xpath, document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;
                return element ? element.textContent : null;
            }
        """)
        
        if not reference_date_str:
            raise Exception('å‚ç…§æ—¥æ™‚ã®è¦ç´ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
        
        self.logger.info(f'å‚ç…§æ—¥æ™‚æ–‡å­—åˆ—ã‚’å–å¾—: {reference_date_str}')
        
        date_part, time_part = reference_date_str.split(' ')
        day, month, year = date_part.split('-')
        reference_date = f'{year}-{month}-{day}'
        
        self.logger.info(f'æ•´å½¢æ¸ˆã¿å‚ç…§æ—¥æ™‚: {reference_date}')
        return reference_date
        
    async def get_mlbb_game_id(self, db):
        """MLBBã®ã‚²ãƒ¼ãƒ IDã‚’å–å¾—"""
        async with db.execute('SELECT id FROM games WHERE game_code = ?', ('mlbb',)) as cursor:

            game_result = await cursor.fetchone()
            if not game_result:
                raise Exception('MLBBã®ã‚²ãƒ¼ãƒ æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
        
        game_id = game_result[0]
        self.logger.info(f'MLBBã®game_id: {game_id}')
        return game_id
        
    async def get_latest_patch_id(self, db, game_id):
        """æœ€æ–°ã®ãƒ‘ãƒƒãƒIDã‚’å–å¾—"""
        async with db.execute(
            'SELECT id FROM patches WHERE game_id = ? ORDER BY release_date DESC LIMIT 1',
            (game_id,)
        ) as cursor:
            patch_result = await cursor.fetchone()
            latest_patch_id = patch_result[0] if patch_result else None
        
        if latest_patch_id:
            self.logger.info(f'æœ€æ–°ã®patch_id: {latest_patch_id}')
        else:
            self.logger.warning('patchesãƒ†ãƒ¼ãƒ–ãƒ«ã«MLBBã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“')
            
        return latest_patch_id
        
    async def save_hero_data(self, hero_meta_data, reference_date):
        """ãƒ’ãƒ¼ãƒ­ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        data_dir = os.path.join(os.path.dirname(__file__), 'data')
        os.makedirs(data_dir, exist_ok=True)
        
        db_path = os.path.join(data_dir, 'moba_log.db')
        async with aiosqlite.connect(db_path) as db:
            await db.execute('PRAGMA foreign_keys = ON;')
            self.logger.info('SQLite (moba_log.db) ã«æ¥ç¶šæˆåŠŸ')
            
            game_id = await self.get_mlbb_game_id(db)
            latest_patch_id = await self.get_latest_patch_id(db, game_id)
            
            await db.execute('BEGIN TRANSACTION')
            try:
                for hero in hero_meta_data:
                    await self.process_single_hero(db, hero, reference_date, game_id, latest_patch_id)
                
                await db.commit()
                self.logger.info('SQLite (moba_log.db) ã¸ã®ã‚³ãƒŸãƒƒãƒˆã«æˆåŠŸ')
            except Exception as db_insert_error:
                await db.rollback()
                raise db_insert_error

    async def update_japanese_names(self, hero_meta_data):
        """ãƒ–ãƒ©ã‚¦ã‚¶ãŒé–‹ã„ã¦ã„ã‚‹é–“ã«æ—¥æœ¬èªåã‚’å–å¾—ãƒ»æ›´æ–°"""
        data_dir = os.path.join(os.path.dirname(__file__), 'data')
        os.makedirs(data_dir, exist_ok=True)
        
        db_path = os.path.join(data_dir, 'moba_log.db')
        async with aiosqlite.connect(db_path) as db:
            await db.execute('PRAGMA foreign_keys = ON;')
            
            game_id = await self.get_mlbb_game_id(db)
            
            # æ—¥æœ¬èªåãŒæœªè¨­å®šã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’ç‰¹å®šã—ã€æ—¥æœ¬èªåã‚’å–å¾—
            for hero in hero_meta_data:
                async with db.execute(
                    'SELECT id, japanese_name FROM characters WHERE english_name = ? AND game_id = ?',
                    (hero['hero'], game_id)
                ) as cursor:
                    character_result = await cursor.fetchone()
                
                if not character_result:
                    # æ–°è¦ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’æŒ¿å…¥
                    await db.execute(
                        'INSERT INTO characters (game_id, english_name) VALUES (?, ?)',
                        (game_id, hero['hero'])
                    )
                    # æŒ¿å…¥ã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®IDã‚’å–å¾—
                    async with db.execute(
                        'SELECT id, japanese_name FROM characters WHERE english_name = ? AND game_id = ?',
                        (hero['hero'], game_id)
                    ) as cursor:
                        character_result = await cursor.fetchone()
                    
                    # æ–°è¦ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒªã‚¹ãƒˆã«è¿½åŠ 
                    self.new_characters.append(hero['hero'])
                    self.logger.info(f"æ–°è¦ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ '{hero['hero']}' ã‚’ characters ãƒ†ãƒ¼ãƒ–ãƒ«ã«æŒ¿å…¥")
                
                character_id = character_result[0]
                japanese_name = character_result[1]
                
                # japanese_nameãŒNULLã®å ´åˆã€MLJPwikiã‹ã‚‰å–å¾—
                if japanese_name is None:
                    japanese_name = await self.get_japanese_name_from_wiki(hero['hero'])
                    if japanese_name:
                        await db.execute(
                            'UPDATE characters SET japanese_name = ? WHERE id = ?',
                            (japanese_name, character_id)
                        )
                        await db.commit()
                        self.logger.info(f"ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ '{hero['hero']}' ã®æ—¥æœ¬èªåã‚’æ›´æ–°: {japanese_name}")
                
    async def process_single_hero(self, db, hero, reference_date, game_id, latest_patch_id):
        """å˜ä¸€ã®ãƒ’ãƒ¼ãƒ­ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ï¼ˆçµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰"""
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼IDã‚’å–å¾—ï¼ˆã“ã®æ™‚ç‚¹ã§æ—¢ã«å­˜åœ¨ã™ã‚‹ã“ã¨ãŒä¿è¨¼ã•ã‚Œã¦ã„ã‚‹ï¼‰
        async with db.execute(
            'SELECT id FROM characters WHERE english_name = ? AND game_id = ?',
            (hero['hero'], game_id)
        ) as cursor:
            character_result = await cursor.fetchone()
        
        if not character_result:
            self.logger.error(f"ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ '{hero['hero']}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
            
        character_id = character_result[0]
        
        # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        async with db.execute(
            'SELECT 1 FROM mlbb_stats WHERE character_id = ? AND reference_date = ? AND rank_info = ? AND patch_id = ?',
            (character_id, reference_date, 'Mythic', latest_patch_id)
        ) as cursor:
            stats_exists = await cursor.fetchone()
        
        if stats_exists:
            self.logger.info(f"'{hero['hero']}' ã®ãƒ‡ãƒ¼ã‚¿ã¯ã™ã§ã«å­˜åœ¨ã™ã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
            return
        
        # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥
        await db.execute("""
            INSERT INTO mlbb_stats 
            (character_id, win_rate, pick_rate, ban_rate, reference_date, rank_info, patch_id)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            character_id,
            hero['win_rate'],
            hero['pick_rate'],
            hero['ban_rate'],
            reference_date,
            'Mythic',
            latest_patch_id
        ))
        self.logger.info(f"mlbb_stats ãƒ†ãƒ¼ãƒ–ãƒ«ã« '{hero['hero']}' ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥")
        
    async def get_japanese_name_from_wiki(self, english_name):
        """MLJPwikiã‹ã‚‰æ—¥æœ¬èªåã‚’å–å¾—"""
        try:
            # æ–°ã—ã„ãƒšãƒ¼ã‚¸ã‚’ä½œæˆã—ã¦wikiã«ã‚¢ã‚¯ã‚»ã‚¹
            wiki_page = await self.browser.new_page()
            await wiki_page.goto('https://mljpwiki.com/heros', wait_until='networkidle')
            
            # altå±æ€§ãŒenglish_nameã¨ä¸€è‡´ã™ã‚‹imgè¦ç´ ã‚’æ¢ã™
            japanese_name = await wiki_page.evaluate("""
                (englishName) => {
                    const imgElements = document.querySelectorAll('#DataTables_Table_0 img');
                    for (const img of imgElements) {
                        if (img.alt === englishName) {
                            // è¦ªè¦ç´ ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
                            const parentText = img.closest('a').textContent.trim();
                            // "{japanese_name} (english_name)" å½¢å¼ã‹ã‚‰æ—¥æœ¬èªåã‚’æŠ½å‡º
                            const match = parentText.match(/^(.+?)\\s*\\(/);
                            if (match) {
                                return match[1].trim();
                            }
                        }
                    }
                    return null;
                }
            """, english_name)
            
            await wiki_page.close()
            
            if japanese_name:
                self.logger.info(f"MLJPwikiã‹ã‚‰æ—¥æœ¬èªåã‚’å–å¾—: {english_name} -> {japanese_name}")
            else:
                self.logger.warning(f"MLJPwikiã§æ—¥æœ¬èªåãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {english_name}")
            
            return japanese_name
            
        except Exception as e:
            self.logger.error(f"MLJPwikiã‹ã‚‰ã®æ—¥æœ¬èªåå–å¾—ã«å¤±æ•—: {english_name} - ã‚¨ãƒ©ãƒ¼: {e}")
            return None
        
    async def record_scraping_status(self, scraping_failed, scraping_error_msg, scraped_data_count=0):
        """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœã‚’ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã«è¨˜éŒ²"""
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            data_dir = os.path.join(os.path.dirname(__file__), 'data')
            os.makedirs(data_dir, exist_ok=True)
            
            status_db_path = os.path.join(data_dir, 'moba_log.db')
            async with aiosqlite.connect(status_db_path) as status_db:
                # MLBBã®ã‚²ãƒ¼ãƒ IDã‚’å–å¾—
                async with status_db.execute('SELECT id FROM games WHERE game_code = ?', ('mlbb',)) as cursor:
                    game_result = await cursor.fetchone()
                    if not game_result:
                        self.logger.error('MLBBã®ã‚²ãƒ¼ãƒ æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
                        return
                
                game_id = game_result[0]
                current_date = datetime.now().strftime('%Y-%m-%d')
                
                await status_db.execute(
                    """INSERT INTO scraper_logs (game_id, scraper_status, error_message, scraper_date)
                       VALUES (?, ?, ?, ?)""",
                    (game_id, 1 if scraping_failed else 0, scraping_error_msg if scraping_failed else None, current_date)
                )
                await status_db.commit()
            self.logger.info('scraper_logs ãƒ†ãƒ¼ãƒ–ãƒ«ã¸ã®è¨˜éŒ²ã«æˆåŠŸ')
            
            # Slacké€šçŸ¥ã‚’é€ä¿¡
            await self.send_slack_notification(scraping_failed, scraping_error_msg, scraped_data_count)
            
        except Exception as status_error:
            self.logger.error(f'scraper_logs ãƒ†ãƒ¼ãƒ–ãƒ«ã¸ã®è¨˜éŒ²ã«å¤±æ•—: {status_error}')

    async def send_slack_notification(self, scraping_failed, scraping_error_msg, scraped_data_count):
        """Slacké€šçŸ¥ã‚’é€ä¿¡"""
        try:
            if scraping_failed:
                # ã‚¨ãƒ©ãƒ¼é€šçŸ¥
                message = f"""ğŸ”´ MLBB ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¤±æ•—
æ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ã‚¨ãƒ©ãƒ¼å†…å®¹: {scraping_error_msg}"""
            else:
                # æˆåŠŸé€šçŸ¥
                new_chars_text = ""
                if self.new_characters:
                    new_chars_text = f"\nğŸ†• æ–°è¦ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼: {', '.join(self.new_characters)}"
                
                message = f"""âœ… MLBB ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Œäº†
æ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
å–å¾—ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {scraped_data_count}ä»¶{new_chars_text}"""
            
            success = send_slack_notification(self.webhook_url, message)
            if success:
                self.logger.info('Slacké€šçŸ¥ã®é€ä¿¡ã«æˆåŠŸ')
            else:
                self.logger.error('Slacké€šçŸ¥ã®é€ä¿¡ã«å¤±æ•—')
                
        except Exception as e:
            self.logger.error(f'Slacké€šçŸ¥é€ä¿¡ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}')
            
    async def run_scraping(self):
        """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å‡¦ç†ã‚’å®Ÿè¡Œ"""
        scraping_failed = False
        scraping_error_msg = ''
        scraped_data_count = 0
        
        try:
            self.logger.info('Mobile Legends ãƒ©ãƒ³ã‚¯ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å‡¦ç†ã‚’é–‹å§‹')
            
            # æœ€æ–°ãƒ‘ãƒƒãƒæƒ…å ±ã‚’å–å¾—
            self.logger.info('æœ€æ–°ãƒ‘ãƒƒãƒæƒ…å ±ã‚’å–å¾—ä¸­...')
            patch_scraper = MLBBPatchScraper()
            patch_success = await patch_scraper.run()
            
            if not patch_success:
                self.logger.warning('æœ€æ–°ãƒ‘ãƒƒãƒæƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™')
            else:
                self.logger.info('æœ€æ–°ãƒ‘ãƒƒãƒæƒ…å ±ã®å–å¾—ãŒå®Œäº†ã—ã¾ã—ãŸ')
            
            await self.launch_browser()
            await self.navigate_to_ranking_page()
            await self.close_privacy_policy()
            await self.select_rank()
            await self.scroll_to_load_all_data()
            
            hero_meta_data = await self.extract_hero_data()
            reference_date = await self.extract_reference_date()
            scraped_data_count = len(hero_meta_data)
            
            # ãƒ–ãƒ©ã‚¦ã‚¶ãŒé–‹ã„ã¦ã„ã‚‹é–“ã«æ—¥æœ¬èªåã‚’å–å¾—ãƒ»æ›´æ–°
            self.logger.info('æ—¥æœ¬èªåã®å–å¾—ãƒ»æ›´æ–°ã‚’é–‹å§‹')
            await self.update_japanese_names(hero_meta_data)
            self.logger.info('æ—¥æœ¬èªåã®å–å¾—ãƒ»æ›´æ–°ãŒå®Œäº†')
            
            await self.close_browser()
            
            await self.save_hero_data(hero_meta_data, reference_date)
            
            self.logger.info('ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãŠã‚ˆã³ãƒ‡ãƒ¼ã‚¿ä¿å­˜å‡¦ç†ã‚’æ­£å¸¸ã«å®Œäº†')
            
        except Exception as error:
            scraping_failed = True
            scraping_error_msg = str(error)
            self.logger.error(f'å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {error}')
            await self.close_browser()
        
        await self.record_scraping_status(scraping_failed, scraping_error_msg, scraped_data_count)

    async def save_hero_icon(self, hero_name, icon_src):
        """ãƒ’ãƒ¼ãƒ­ãƒ¼ã®ã‚¢ã‚¤ã‚³ãƒ³ç”»åƒã‚’ä¿å­˜"""
        try:
            # hero_imagesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            hero_images_dir = os.path.join(os.path.dirname(__file__), 'hero_images')
            os.makedirs(hero_images_dir, exist_ok=True)
            
            # ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            async with aiohttp.ClientSession() as session:
                async with session.get(icon_src) as response:
                    if response.status == 200:
                        image_data = await response.read()
                        
                        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’hero_nameã«ã—ã¦.webpå½¢å¼ã§ä¿å­˜
                        file_path = os.path.join(hero_images_dir, f'{hero_name}.webp')
                        with open(file_path, 'wb') as f:
                            f.write(image_data)
                        
                        self.logger.info(f"ãƒ’ãƒ¼ãƒ­ãƒ¼ã‚¢ã‚¤ã‚³ãƒ³ã‚’ä¿å­˜: {file_path}")
                    else:
                        self.logger.warning(f"ç”»åƒã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {hero_name} - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status}")
        except Exception as e:
            self.logger.error(f"ãƒ’ãƒ¼ãƒ­ãƒ¼ã‚¢ã‚¤ã‚³ãƒ³ã®ä¿å­˜ã«å¤±æ•—: {hero_name} - ã‚¨ãƒ©ãƒ¼: {e}")

async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    scraper = MLBBScraper()
    await scraper.run_scraping()

# ãƒ¡ã‚¤ãƒ³é–¢æ•°ã®å®Ÿè¡Œ
if __name__ == "__main__":
    asyncio.run(main())

